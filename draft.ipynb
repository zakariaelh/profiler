{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List, Tuple, Optional, Literal\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "import subprocess\n",
    "from github import Github\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "ANTHROPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY')\n",
    "GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN')\n",
    "github_client = Github(GITHUB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(command, cwd=None):\n",
    "    \"\"\"Utility function to run shell commands within a specific directory.\"\"\"\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, cwd=cwd)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error: {result.stderr.decode('utf-8')}\")\n",
    "    else:\n",
    "        print(result.stdout.decode('utf-8'))\n",
    "\n",
    "def checkout_branch(repo_dir, branch_name):\n",
    "    \"\"\"Checkout to a specific branch.\"\"\"\n",
    "    run_command(f\"git checkout {branch_name}\", cwd=repo_dir)\n",
    "\n",
    "def checkout_commit(repo_dir, commit_hash):\n",
    "    \"\"\"Checkout to a specific commit.\"\"\"\n",
    "    run_command(f\"git checkout {commit_hash}\", cwd=repo_dir)\n",
    "\n",
    "def checkout(repo_dir, branch_name, commit_hash):\n",
    "    checkout_branch(repo_dir, branch_name)\n",
    "    checkout_commit(repo_dir, commit_hash)\n",
    "\n",
    "def get_file_content(repo_dir: str, file_path: str) -> Optional[str]:\n",
    "    full_path = os.path.join(repo_dir, file_path)\n",
    "    with open(full_path, 'r') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pr_information(owner: str, repo: str, pr_number: int, auth_token: str) -> dict:\n",
    "    repo = github_client.get_repo(f\"{owner}/{repo}\")\n",
    "    pr = repo.get_pull(pr_number)\n",
    "    print(f'fetching PR information for {pr_number}')\n",
    "    return pr.raw_data\n",
    "def get_file_content(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch file content. Status code: {response.status_code}\")\n",
    "\n",
    "def add_line_numbers(content):\n",
    "    lines = content.split('\\n')\n",
    "    numbered_lines = [f\"<{i+1}>{line}\" for i, line in enumerate(lines)]\n",
    "    return '\\n'.join(numbered_lines)\n",
    "\n",
    "def remove_line_numbers(content):\n",
    "    lines = content.split('\\n')\n",
    "    unnumbered_lines = [re.sub(r'<\\d+>\\s', '', line) for line in lines]\n",
    "    return '\\n'.join(unnumbered_lines)\n",
    "\n",
    "def add_file_content_inplace(file) -> str:\n",
    "    # get file content \n",
    "    file_content = get_file_content(file['raw_url'])\n",
    "\n",
    "    # add line number to each line \n",
    "    numbered_content = add_line_numbers(file_content)\n",
    "\n",
    "    # update file dict  \n",
    "    file['content'] = numbered_content\n",
    "    file['raw_content'] = file_content\n",
    "\n",
    "\n",
    "def get_pr_files(pull_request) -> List[dict]:\n",
    "    return [i.raw_data for i in pull_request.get_files()]\n",
    "\n",
    "def get_prompt():\n",
    "    return \"\"\"\n",
    "    Given the following information about a file that has been changed and its latency profile, what optimizations would you suggest to reduce latency? Only suggest changes when you're confident they will improve the latency, as the results will be evaluated by a profiler.\n",
    "\n",
    "    File path: {file_name}\n",
    "    \n",
    "    File content: {file_content}\n",
    "    \n",
    "    File changes: {patch}\n",
    "\n",
    "    Latency profile results: {latency_results}\"\n",
    "\n",
    "    Please provide specific optimization suggestions based on this information. Return the file updated with the changes made.\n",
    "    \"\"\"\n",
    "\n",
    "def get_system_message():\n",
    "    return \"\"\"You are an AI assistant and a smart software engineer. You are specialized in improving code performance and runtime.\"\"\"\n",
    "\n",
    "def get_changes_from_llm(file, latency_profile):\n",
    "    prompt = get_prompt(file, latency_profile=latency_profile)\n",
    "\n",
    "    changes = send_prompt_to_llm(prompt)\n",
    "\n",
    "    return changes \n",
    "\n",
    "\n",
    "def get_updated_file(file, latency_profile):\n",
    "    pass \n",
    "\n",
    "def create_commit():\n",
    "    pass \n",
    "\n",
    "def create_pr():\n",
    "    pass \n",
    "\n",
    "\n",
    "def send_prompt_to_llm(prompt):\n",
    "    client = Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "    message = client.messages.create(\n",
    "        max_tokens=4096,\n",
    "        system=[\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": get_system_message()\n",
    "            }\n",
    "        ],\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Below is the original file with the updated optimizations made:\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "    )\n",
    "    resp = message.content\n",
    "\n",
    "    print(f\"Usage: {message.usage}\")\n",
    "    if resp:\n",
    "        return resp[0].text\n",
    "\n",
    "\n",
    "def get_pull_requests(owner, repo):\n",
    "    \"\"\"\n",
    "    Retrieves all pull requests for a given repository.\n",
    "    \n",
    "    Args:\n",
    "        owner (str): The owner of the repository.\n",
    "        repo (str): The name of the repository.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of PullRequest objects.\n",
    "    \"\"\"\n",
    "    repository = github_client.get_repo(f\"{owner}/{repo}\")\n",
    "    pull_requests = list(repository.get_pulls(state='open'))\n",
    "    return pull_requests\n",
    "\n",
    "\n",
    "def pr_files(owner: str, repo: str, pr_number: int):\n",
    "    repo_obj = github_client.get_repo(f\"{owner}/{repo}\")\n",
    "    pr = repo_obj.get_pull(pr_number)\n",
    "    pr_files = get_pr_files(pr)\n",
    "\n",
    "    for file in pr_files:\n",
    "        # add content of the file \n",
    "        add_file_content_inplace(file)\n",
    "    \n",
    "    return pr_files\n",
    "\n",
    "class CodeChange(BaseModel):\n",
    "    \"\"\"Changes to make to the file.\"\"\"\n",
    "\n",
    "    change_type: Literal[\"delete\", \"modify\", \"add_after\"] = Field(description=\"The type of change to make.\")\n",
    "    line_start: int = Field(description=\"The starting line of the change. Please verify that the line number is correct.\")\n",
    "    line_end: int = Field(description=\"The end line of the change. Please verify that the line number is correct.\")\n",
    "    content: str = Field(description=\"The code changes to make to these lines\")\n",
    "\n",
    "class ChangedCode(BaseModel):\n",
    "    \"\"\"The code snippet with the patch applied.\"\"\"\n",
    "\n",
    "    content: str = Field(description=\"code snippet with the code applied.\")\n",
    "\n",
    "class Patch(BaseModel):\n",
    "    start: Optional[int] = Field(description=\"start line of the patch\")\n",
    "    end: Optional[int] = Field(description=\"end line of the patch\")\n",
    "    code_snippet: Optional[str] = Field(description=\"original piece of code to apply patch to\")\n",
    "    patch: Optional[str] = Field(description=\"code snippet after applying the patch\")\n",
    "\n",
    "class FileChange(BaseModel):\n",
    "    \"\"\"List of all the changes to make to the file.\"\"\"\n",
    "    changes: list[CodeChange] = Field(description=\"List of specific code changes\")\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self):\n",
    "        llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "        structured_llm = llm.with_structured_output(FileChange)\n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", get_system_message()),\n",
    "            (\"user\", get_prompt())\n",
    "        ])\n",
    "\n",
    "\n",
    "        self.runnable = prompt_template | structured_llm\n",
    "\n",
    "    def get_response(self, file: dict, latency_results: dict) -> FileChange:\n",
    "        res = self.runnable.invoke(\n",
    "            {\n",
    "                \"file_name\": file['filename'], \n",
    "                \"file_content\": file['content'], \n",
    "                \"patch\": file['patch'],\n",
    "                \"latency_results\": latency_results\n",
    "            })\n",
    "        \n",
    "        return res \n",
    "    \n",
    "class LineChangeFixer:\n",
    "    def __init__(self):\n",
    "        llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "        structured_llm = llm.with_structured_output(ChangedCode)\n",
    "        system = \"\"\"\n",
    "        You are a smart and cautious software engineer\n",
    "        \"\"\"\n",
    "        prompt = \"\"\"\n",
    "        Given the following snippet of code, apply the following patches to it.\n",
    "\n",
    "        Code Snippet:\n",
    "        {code_snippet}\n",
    "        \n",
    "        Patches: \n",
    "        {patch}\n",
    "        \"\"\"\n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system),\n",
    "            (\"user\", prompt)\n",
    "        ])\n",
    "\n",
    "\n",
    "        self.runnable = prompt_template | structured_llm\n",
    "\n",
    "    def get_response(self, file: dict, code_change_list: List[CodeChange]) -> Patch:\n",
    "        if not code_change_list:\n",
    "            return Patch(patch=None)\n",
    "        st = min([i.line_start for i in code_change_list])\n",
    "        end = max([i.line_end for i in code_change_list])\n",
    "        adjusted_st = max(0, st - 10)\n",
    "        adjusted_end = end + 10\n",
    "        # split file content by lines \n",
    "        code_snippet = '\\n'.join(file['content'].split('\\n')[adjusted_st:adjusted_end])\n",
    "        res = self.runnable.invoke(\n",
    "            {\n",
    "                \"code_snippet\": code_snippet, \n",
    "                \"patch\": [i.model_dump() for i in code_change_list]\n",
    "            })\n",
    "\n",
    "        \n",
    "        return Patch(start=adjusted_st, end=adjusted_end, code_snippet=code_snippet, patch=res.content)\n",
    "    \n",
    "def update_file(file: dict, updated_content: str):\n",
    "    # load file \n",
    "    local_file_path = f\"../PyGithub/{file['filename']}\"\n",
    "    \n",
    "    # Write the updated content to the file\n",
    "    with open(local_file_path, 'w') as f:\n",
    "        f.write(updated_content)\n",
    "\n",
    "    print(f'{file[\"filename\"]} has been updated')\n",
    "\n",
    "def apply_patch_to_file(file: dict, patch: Patch):\n",
    "    # apply the patch to the file \n",
    "    lines = file['raw_content'].split('\\n')\n",
    "    # remove line numbers from the patch \n",
    "    tmp = remove_line_numbers(tmp['patch'].content)\n",
    "    new_lines = tmp.split('\\n')\n",
    "    lines[patch.start:patch.end] = new_lines\n",
    "    new_file_content = '\\n'.join(lines)\n",
    "\n",
    "    update_file(file, new_file_content)\n",
    "\n",
    "def combine_close_changes(changes: List[CodeChange], max_distance: int = 10) -> List[List[CodeChange]]:\n",
    "    if not changes:\n",
    "        return []\n",
    "\n",
    "    # Sort changes by start line\n",
    "    sorted_changes = sorted(changes, key=lambda x: x.line_start)\n",
    "    \n",
    "    combined = []\n",
    "    current_group = [sorted_changes[0]]\n",
    "\n",
    "    for change in sorted_changes[1:]:\n",
    "        if change.line_start - current_group[-1].line_end <= max_distance:\n",
    "            current_group.append(change)\n",
    "        else:\n",
    "            combined.append(current_group)\n",
    "            current_group = [change]\n",
    "\n",
    "    # Add the last group\n",
    "    combined.append(current_group)\n",
    "\n",
    "    return combined\n",
    "\n",
    "    \n",
    "def main(owner, repo, pr_number):\n",
    "    # get latency profile \n",
    "    latency_profile = \"100ms\"\n",
    "    # get files in the pr  \n",
    "    pr_files = get_pr_files(owner, repo, pr_number)\n",
    "\n",
    "    for file in tqdm(pr_files):\n",
    "        # get code changes \n",
    "        res = LLM().get_response(file, latency_results=latency_profile)\n",
    "        code_change_list = combine_close_changes(res.changes)\n",
    "        patch = LineChangeFixer().get_response(file=file, code_change_list=code_change_list)\n",
    "        # get changes and update \n",
    "        apply_patch_to_file(patch)\n",
    "\n",
    "def remove_line_numbers(text: str) -> str:    \n",
    "    return re.sub(r'<\\d+>', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "owner=\"pygithub\"\n",
    "repo = \"pygithub\"\n",
    "pr_list = get_pull_requests(owner, repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files changed: 3\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "pr = random.choice(pr_list)\n",
    "if len(list(pr.get_files())) < 4:\n",
    "    files = pr_files(owner, repo, pr.number)\n",
    "    print(f'Number of files changed: {len(files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen file: tests/ReplayData/Organization.testGetRepoSecurityAdvisories.txt\n",
      "0 suggested changes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[205], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m code_change_list \u001b[38;5;241m=\u001b[39m combine_close_changes(res\u001b[38;5;241m.\u001b[39mchanges)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mchanges)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m suggested changes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mLineChangeFixer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_change_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_change_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[200], line 202\u001b[0m, in \u001b[0;36mLineChangeFixer.get_response\u001b[0;34m(self, file, code_change_list)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, file: \u001b[38;5;28mdict\u001b[39m, code_change_list: List[CodeChange]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Patch:\n\u001b[0;32m--> 202\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline_start\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcode_change_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([i\u001b[38;5;241m.\u001b[39mline_end \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m code_change_list])\n\u001b[1;32m    204\u001b[0m     adjusted_st \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, st \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "file = random.choice(files)\n",
    "print(f'Chosen file: {file[\"filename\"]}')\n",
    "res = LLM().get_response(file, latency_results=\"100ms\")\n",
    "print(f'{len(res.changes)} suggested')\n",
    "code_change_list = combine_close_changes(res.changes)\n",
    "print(f'{len(res.changes)} suggested changes')\n",
    "tmp = LineChangeFixer().get_response(file=file, code_change_list=code_change_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
